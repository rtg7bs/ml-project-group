# What is an observation in your study?
An observation in our study is an individual and includes data on factors that may 
contribute to that individual’s risk of developing obesity. Each observation can include dietary behaviors, such as calorie intake or the number of meals/day, and physical lifestyle __ such as frequency of exercise, intensity, and mode of transportation used. Our data also includes information on water and alcohol consumption. By defining each row in our dataset as an ‘observation’, we can analyze how these factors interact and contribute to various levels of obesity risk in the population. 
# What models or algorithms do you plan to use in your analysis? How?
For this analysis, logistic regression can be employed for its interpretability and ability to identify the significance of various lifestyles that are attributed to obesity. It can help us to identify which lifestyle factors (like calorie intake or physical activity frequency) are statistically significant in predicting different obesity categories.  Another mode of analysis can be decision trees which are ideal for capturing non-linear interactions, especially among dietary, physical, and lifestyle factors. These decision trees can reveal, for example, that individuals who exercise infrequently and consume a higher amount of calories are at a higher obesity risk. This will help in understanding how multiple variables impact obesity. A kNN model can be used as a comparison model that can reveal that individuals with similar lifestyles may have a similar obesity risk. 


#Q5
What are weaknesses that you anticipate being an issue? How will you deal with them if they come up? If your approach fails, what might you learn from this unfortunate outcome?
Some weaknesses that we anticipate being an issue is perhaps the distribution in the population size, known as a class imbalance. This could be particularly troublesome if we decided to do a supervised learning model, leading to biased or inaccurate decisions amongst our clusters. If one population is overrepresented the model will learn to prioritize it, leading to high accuracy for the majority class but low accuracy on the minority.  
One way of combating this issue would be to undersample the majority class or oversample the minority to balance out the differences.  An algorithm like balanced random forest can apply higher weights made by errors in the minority class, allowing the model to be more sensitive in these cases. 

#Feature Engineering: How will you prepare the data specifically for your analysis? For example, are there many variables that should be one-hot encoded? Do you have many correlated numeric variables, for which PCA might be a useful tool?
Specific categories will have a binary hot encoded variable, for example smoking or non smoking/ family history of being overweight. These would be labeled as either 1 or 0. However for transportation used we might have to encode for more than three variables this includes public transportation, walking, along with automobile and mobile (which can also be further categorized). We want to make sure that we use the hot encoded method since our categorical data are not ranked or correlated with one another. This can help prevent the model from treating the categorical variables as being ordinal. 
I don’t think PCA would be relevant for us since we would be doing supervised learning but there is a chance this could change. If we decide to use it it would be useful to splice out the different categories in the automobile and mobile categories where some are more variables are more frequent than others. 